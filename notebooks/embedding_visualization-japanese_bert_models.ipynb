{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9a8c5b",
   "metadata": {
    "id": "9f9a8c5b"
   },
   "source": [
    "# BERTの埋め込み空間の可視化\n",
    "\n",
    "このノートブックでは、BERTの埋め込み空間の可視化を行います。\n",
    "可視化を行うことで、各モデルの特徴を調査することができます。\n",
    "\n",
    "コードは、[BERTの埋め込み空間の可視化を最速で](https://zenn.dev/hpp/articles/d347bcb7ed0fc0)の記事を、参考に実装しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce28e8",
   "metadata": {
    "id": "1bce28e8"
   },
   "source": [
    "## ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c32bd-2efa-42a7-b92b-2866bcd06e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nagisa_bert # taishi-i/nagisa_bert\n",
    "!pip install fugashi\n",
    "!pip install ipadic # cl-tohoku/bert-base-japanese-whole-word-masking\n",
    "!pip install unidic-lite # cl-tohoku/bert-base-japanese-v2\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "!pip install holoviews\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f283b",
   "metadata": {
    "id": "ae1f283b"
   },
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d952f7b",
   "metadata": {
    "id": "4d952f7b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers import AutoModel\n",
    "from nagisa_bert import NagisaBertTokenizer\n",
    "from transformers import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756e7a0",
   "metadata": {
    "id": "f756e7a0"
   },
   "source": [
    "## 利用する言語モデル（BERTモデルの種類）の指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a3739",
   "metadata": {
    "id": "012a3739"
   },
   "outputs": [],
   "source": [
    "model_name = \"taishi-i/nagisa_bert\"\n",
    "# model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "# model_name = \"cl-tohoku/bert-base-japanese-v2\"\n",
    "\n",
    "if model_name == \"taishi-i/nagisa_bert\":\n",
    "    tokenizer = NagisaBertTokenizer.from_pretrained(model_name)\n",
    "else:\n",
    "    tokenizer = BertJapaneseTokenizer.from_pretrained(model_name) \n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d9532",
   "metadata": {
    "id": "c53d9532"
   },
   "source": [
    "## 可視化対象とするトークンの選択\n",
    "\n",
    "ここでは、文字数の多いトークンを順に3000件選びます。\n",
    "サブワードとなるトークンは対象とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dc158",
   "metadata": {
    "id": "c69dc158"
   },
   "outputs": [],
   "source": [
    "NUM_WORDS = 3000\n",
    "\n",
    "token_embeddings = model.get_input_embeddings().weight.clone()\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "vectors = {}\n",
    "words = []\n",
    "for word, idx in sorted(vocab.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "    if \"##\" not in word:\n",
    "        words.append(word)\n",
    "        vectors[idx] = token_embeddings[idx].detach().numpy().copy()\n",
    "        if len(vectors) > NUM_WORDS:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151eaa74",
   "metadata": {
    "id": "151eaa74"
   },
   "source": [
    "## TSNEによる次元圧縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad8051",
   "metadata": {
    "id": "74ad8051",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "reduced_vectors = tsne.fit_transform(np.array(list(vectors.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaacf78a",
   "metadata": {
    "id": "eaacf78a"
   },
   "source": [
    "## 埋め込み空間の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32980e",
   "metadata": {
    "id": "dc32980e"
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "hv.extension('plotly')\n",
    "\n",
    "points = hv.Points(reduced_vectors)\n",
    "\n",
    "labels = hv.Labels(\n",
    "    {('x', 'y'): reduced_vectors, 'text': [token for token, _ in zip(words, reduced_vectors)]}, \n",
    "    ['x', 'y'], \n",
    "    'text'\n",
    ")\n",
    "\n",
    "(points * labels).opts(\n",
    "    opts.Labels(xoffset=0.05, yoffset=0.05, size=14, padding=0.2, width=1000, height=1000),\n",
    "    opts.Points(color='black', marker='x', size=3),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
